container: "docker://maxfieldkelsey/te-seq:v1.1"

import os
import pandas as pd
from pathlib import Path
import csv

pepfile: "conf/project_config_srna.yaml"
peptable = pep.sample_table
peptable.to_csv("conf/peptable_srna.csv", index = False, quoting=csv.QUOTE_NONNUMERIC)


#need to use the config["srna"]["samples"] and not sample_table["sample_name"], deseq order matters and is based on conf$samples
samples = config["srna"]["samples"]
contrasts = config["srna"]["contrasts"]
counttypes = config["srna"]["counttypes"]
peptable = pd.read_csv("conf/peptable_srna.csv")

#tag FILESTRUCTURE
paths = [
    "srna/qc",
    "srna/benchmarks"
    ]
for path in paths:
    for sample in samples:
        for counttype in config["srna"]["counttypes"]:
            for contrast in config["srna"]["contrasts"]:
                os.makedirs(path.format(sample=sample, counttype=counttype, contrast=contrast), exist_ok = True)

#tag FUNCTIONS
import re
def inferLibraryType():
    try: 
        f = open("srna/qc/library_type.txt")
        data = f.read()
        lines = re.findall('Fraction.*', data)
        pctMapped = [float(line.split(": ")[1]) for line in lines]
        if pctMapped[1] > 0.75:
            libraryType = "forward"
        elif pctMapped[2] > 0.75:
            libraryType = "reverse"
        else:
            libraryType = "unstranded"
        return libraryType
    except:
        return "didn't run infer library type yet"

def getFeatureCountsStrandParam():
    libraryType = inferLibraryType()
    if libraryType == "forward":
        strandParam = "1"
    elif libraryType == "reverse":
        strandParam = "2"
    elif libraryType == "unstranded":
        strandParam = "0"
    else:
        strandParam = "didn't run infer library type yet"
    return strandParam


def getTelescopeStrandParam():
    libraryType = inferLibraryType()
    if libraryType == "forward":
        if config["srna"]["library_type"] == "PE":
            strandParam = "FR"
        elif config["srna"]["library_type"] == "SE":
            strandParam = "F"
    elif libraryType == "reverse":
        if config["srna"]["library_type"] == "PE":
            strandParam = "RF"
        elif config["srna"]["library_type"] == "SE":
            strandParam = "R"
    elif libraryType == "unstranded":
        strandParam = "None"
    else:
        strandParam = "didn't run infer library type yet"
    return strandParam

def getFpkmCountStrandParam():
    libraryType = inferLibraryType()
    if libraryType == "forward":
        if config["srna"]["library_type"] == "PE":
            strandParam = "1++,1--,2+-,2-+"
        elif config["srna"]["library_type"] == "SE":
            strandParam = "++,--"
    elif libraryType == "reverse":
        if config["srna"]["library_type"] == "PE":
            strandParam = "1+-,1-+,2++,2--"
        elif config["srna"]["library_type"] == "SE":
            strandParam = "+-,-+"
    elif libraryType == "unstranded":
        strandParam = "None"
    else:
        strandParam = "didn't run infer library type yet"
    return strandParam

# def enforce_symlink(wildcards):
#     if config["srna"]["symlink_aref"]["response"] == "yes":
#         return "aref.symlinked.outfile"
#     else:
#         return ""

#tag PREPROCESSING
rule subsample_fastq:
    input:
        r1=lambda wildcards: peptable.loc[peptable["sample_name"] == wildcards.sample, "file_path_R1"].iloc[0],
        r2=lambda wildcards: peptable.loc[peptable["sample_name"] == wildcards.sample, "file_path_R2"].iloc[0]
    output:
        r1 = "srna/outs/{sample}/subsampled/{sample}_1.subsampled.fastq.gz",
        r2 = "srna/outs/{sample}/subsampled/{sample}_2.subsampled.fastq.gz"
    conda:
        "omics"
    shell:
        """
seqkit head -n 1000000 {input.r1} | gzip > {output.r1}
seqkit head -n 1000000 {input.r2} | gzip > {output.r2}
        """


rule fastp_PE:
    input:
        r1=lambda wildcards: peptable.loc[peptable["sample_name"] == wildcards.sample, "file_path_R1"].iloc[0],
        r2=lambda wildcards: peptable.loc[peptable["sample_name"] == wildcards.sample, "file_path_R2"].iloc[0]
    priority: 100
    threads: 6
    retries: 3
    benchmark:
        "srna/benchmarks/fastp_PE/{sample}.tsv"
    output:
        r1 = "srna/outs/{sample}/trimmedReads/{sample}_1.trimmed.fastq.gz",
        r2 = "srna/outs/{sample}/trimmedReads/{sample}_2.trimmed.fastq.gz",
        json = "srna/outs/{sample}/trimmedReads/fastp.json",
        html = "srna/outs/{sample}/trimmedReads/fastp.html"
    conda:
        "qc"
    shell:
        """
fastp -i {input.r1} -I {input.r2} -o {output.r1} -O {output.r2} --json {output.json} --html {output.html} --detect_adapter_for_pe --thread {threads}
        """

rule fastp_SE:
    input:
        r1=lambda wildcards: peptable.loc[peptable["sample_name"] == wildcards.sample, "file_path_R1"].iloc[0],
    priority: 100
    threads: 6
    retries: 3
    benchmark:
        "srna/benchmarks/fastp_SE/{sample}.tsv"
    output:
        r1 = "srna/outs/{sample}/trimmedReads/{sample}_1.trimmed.fastq.gz",
        json = "srna/outs/{sample}/trimmedReads/fastp.json",
        html = "srna/outs/{sample}/trimmedReads/fastp.html"
    conda:
        "qc"
    shell:
        """
fastp -i {input.r1} -o {output.r1} --json {output.json} --html {output.html} --thread {threads}
        """


#tag QC

rule mycoplasmaCheck:
    input:
        r1 = "srna/outs/{sample}/trimmedReads/{sample}_1.trimmed.fastq.gz"
    output:
        bam = "srna/qc/mycoplasma/mycoplasma{sample}.sorted.bam"
    benchmark:
        "srna/benchmarks/mycoplasmaCheck/{sample}.tsv"
    threads: 20
    resources:
        mem_mb  = 60000
    conda:
        "omics"
    shell:
        """
mkdir -p $(dirname {output.bam})
bowtie2 --threads 10 -x resources/genomes/mycoplasma/mycoplasma_index -U {input.r1} | samtools view -@8 -bS - > {output.bam}.temp
samtools sort -@8 -m4g {output.bam}.temp > {output.bam}
rm {output.bam}.temp
samtools index  -@6 {output.bam} 
samtools idxstat -@6 {output.bam} 
samtools stats {output.bam} > {output.bam}.stats.txt
        """


rule inferLibraryType:
    input:
        bam = expand("srna/outs/{sample}/star_output/{sample}.sorted.primary.bam", sample = samples[0])
    output:
        librarytype = "srna/qc/library_type.txt"
    benchmark:
        "srna/benchmarks/inferLibraryType/inferLibraryType.tsv"
    params:
        gtf = config["srna"]['annotation_genes_bed12'],
    resources:
        mem_mb  = 30000
    conda:
        "rseqc"
    shell:
        """
infer_experiment.py -r {params.gtf} -i {input.bam} > {output.librarytype}
        """

rule multiqc:
    input:
        bams = expand("srna/outs/{sample}/star_output/{sample}.sorted.bam.stats.txt", sample = samples),
        deseq = lambda w: [expand("srna/results/agg/deseq/{counttype}/counttablesizenormed.csv", counttype = config["srna"]["counttypes"]) if len(config["srna"]["levels"]) > 1 else []][0]
    output:
        "srna/qc/multiqc/multiqc_report.html"
    benchmark:
        "srna/benchmarks/multiqc/multiqc.tsv"
    conda:
        "qc"
    shell:
        """
mkdir -p $(dirname {output})
multiqc -f -o $(dirname {output}) --export ./srna/
        """

#tag ALIGNMENT
def get_proper_ref_starindex(wildcards):
    if config["srna"]["per_sample_ref"] == "yes":
        if config["aref"]["patch_ref"] == "yes":
            return "aref/default/%s.snp_patched_indeces/star_index"%(wildcards.sample)
        else: 
            return "aref/default/%s_indeces/star_index"%(wildcards.sample)
    else:
        if config["aref"]["patch_ref"] == "yes":
            return "aref/default/A.REF.snp_patched_indeces/star_index"
        else:
            return "aref/default/A.REF_indeces/star_index"

rule alignSTAR_PE:
    input:
        r1 = "srna/outs/{sample}/trimmedReads/{sample}_1.trimmed.fastq.gz",
        r2 = "srna/outs/{sample}/trimmedReads/{sample}_2.trimmed.fastq.gz",
        aref = "aref.done.outfile"
    retries: 3
    params:
        index = get_proper_ref_starindex
    output:
        bam = temp("srna/outs/{sample}/star_output/Aligned.out.sam")
    benchmark:
        "srna/benchmarks/alignSTAR_PE/{sample}.tsv"
    threads: 8
    resources:
        mem_mb  = 60000
    conda:
        "star"
    shell:
        """
STAR --genomeDir {params.index} --readFilesCommand zcat --readFilesIn {input.r1} {input.r2} --outFileNamePrefix $(dirname {output.bam})/ --runThreadN {threads} --winAnchorMultimapNmax 1000 --outFilterMultimapNmax 1000 --limitOutSAMoneReadBytes 1000000
        """

#tag COUNTS
rule featurecounts_genes_PE:
    input:
        primaryBams = expand("srna/outs/{sample}/star_output/{sample}.sorted.primary.bam", sample = samples),
        libtype = "srna/qc/library_type.txt",
    output:
        countsmessy = "srna/outs/agg/featurecounts_genes/counts_messy.txt",
        counts = "srna/outs/agg/featurecounts_genes/counts.txt",
        readassignment = expand("srna/outs/agg/featurecounts_genes/{sample}.sorted.primary.bam.featureCounts", sample = samples)
    benchmark:
        "srna/benchmarks/featurecounts_genes_PE/featurecounts_genes_PE.tsv"
    params: 
        gtf = config["srna"]['annotation_genes'],
        featureCountsstrandparam = getFeatureCountsStrandParam()
    conda: "omics"
    threads: 4
    shell: 
        """
echo {params.featureCountsstrandparam}
featureCounts -p -s {params.featureCountsstrandparam} -O -M -T {threads} -t exon -a {params.gtf} -o {output.countsmessy} -R CORE  --minOverlap 25 --fraction --primary {input.primaryBams}
cut -f1,7- {output.countsmessy} | awk 'NR > 1' > {output.counts}
        """

rule featurecounts_genesandrtes_PE:
#for non-telescope based counts for RTEs
    input:
        sortedSTARbams = expand("srna/outs/{sample}/star_output/{sample}.sorted.primary.bam", sample = samples),
        libtype = "srna/qc/library_type.txt"
    output:
        countsmessy = "srna/outs/agg/featurecounts_genesandrtes/counts_messy.txt",
        counts = "srna/outs/agg/featurecounts_genesandrtes/counts.txt",
    params: 
        gtf = "aref/default/A.REF_annotations/A.REF_repeatmasker_refseq.complete.gtf",
        featureCountsstrandparam = getFeatureCountsStrandParam()
    benchmark:
        "srna/benchmarks/featurecounts_genesandrtes_PE/featurecounts_genesandrtes_PE.tsv"
    conda:
        "omics"
    resources:
        cpus_per_task =10,
        runtime = 3000,
        mem_mb = 32000,
    shell: 
        """
echo {params.featureCountsstrandparam}
featureCounts -p -s {params.featureCountsstrandparam} -M -T 8 --primary --ignoreDup --largestOverlap -a {params.gtf} -o {output.countsmessy} {input.sortedSTARbams}
cut -f1,7- {output.countsmessy} | awk 'NR > 1' > {output.counts}
        """

rule alignSTAR_SE:
    input:
        r1 = "srna/outs/{sample}/trimmedReads/{sample}_1.trimmed.fastq.gz"
    retries: 3
    params:
        index = get_proper_ref_starindex
    output:
        bam = temp("srna/outs/{sample}/star_output/Aligned.out.sam")
    benchmark:
        "srna/benchmarks/alignSTAR_SE/{sample}.tsv"
    threads: 8
    resources:
        mem_mb  = 60000
    conda:
        "star"
    shell:
        """
STAR --genomeDir {params.index} --readFilesCommand zcat --readFilesIn {input.r1} --outFileNamePrefix $(dirname {output.bam})/ --runThreadN {threads} --winAnchorMultimapNmax 100 --outFilterMultimapNmax 100
        """

rule featurecounts_genes_SE:
    input:
        sortedSTARbams = expand("srna/outs/{sample}/star_output/{sample}.sorted.primary.bam", sample = samples),
        libtype = "srna/qc/library_type.txt"
    output:
        countsmessy = "srna/outs/agg/featurecounts_genes/counts_messy.txt",
        counts = "srna/outs/agg/featurecounts_genes/counts.txt",
        countsstrandnonspecificmessy = "srna/outs/agg/featurecounts_genes/countsstrandnonspecific_messy.txt",
        countsstrandnonspecific = "srna/outs/agg/featurecounts_genes/countsstrandnonspecific.txt",
        metafeaturecounts = "srna/outs/agg/featurecounts_genes/metafeature.counts.txt"
    benchmark:
        "srna/benchmarks/featurecounts_genes_SE/featurecounts_genes_SE.tsv"
    params: 
        gtf = config["srna"]['annotation_genes'],
        featureCountsstrandparam = getFeatureCountsStrandParam()
    conda:
        "omics"
    threads: 4
    shell: 
        """
echo {params.featureCountsstrandparam}
featureCounts -s {params.featureCountsstrandparam} -T {threads} -t exon -a {params.gtf} -o {output.countsmessy} {input.sortedSTARbams}
cut -f1,7- {output.countsmessy} | awk 'NR > 1' > {output.counts}
featureCounts -s {params.featureCountsstrandparam} -T {threads} -B -O -a {params.gtf} -o {output.countsstrandnonspecificmessy} {input.sortedSTARbams}
cut -f1,7- {output.countsstrandnonspecificmessy} | awk 'NR > 1' > {output.countsstrandnonspecific}
featureCounts -T {threads} -B -O -a {params.gtf} -o {output.metafeaturecounts} {input.sortedSTARbams}
        """

#tag ALIGNMENT UTILITIES
rule sortIndexBam:
    input:
        sam = "srna/outs/{sample}/star_output/Aligned.out.sam"
    output:
        sortedbam =  "srna/outs/{sample}/star_output/{sample}.sorted.bam",
        stats =  "srna/outs/{sample}/star_output/{sample}.sorted.bam.stats.txt",
        index = "srna/outs/{sample}/star_output/{sample}.sorted.bam.bai"
    benchmark:
        "srna/benchmarks/sortIndexBam/{sample}.tsv"
    resources:
        cpus_per_task =10,
        mem_mb = 64000
    conda:
        "omics"
    shell:
        """
samtools view -@8 -b {input.sam} > {output.sortedbam}.temp
samtools sort -@8 -m4g {output.sortedbam}.temp > {output.sortedbam}
rm {output.sortedbam}.temp
samtools index  -@6 {output.sortedbam}
samtools stats {output.sortedbam} > {output.stats}
        """


rule common_filterForPrimaryAlignments:
    input:
        "srna/{path}.sorted.bam"
    output:
        bam =  "srna/{path}.sorted.primary.bam",
        bamindex = "srna/{path}.sorted.primary.bam.bai"
    benchmark:
        "srna/benchmarks/common_filterForPrimaryAlignments/{path}.tsv"
    threads: 4
    conda:
        "omics"
    shell: 
        """
samtools view -b -F 0x800 -F 0x100 -F 0x400 {input} > {output.bam}
samtools index {output.bam}
        """ 

rule collateBam:
    input:
        sortedBam = "srna/outs/{sample}/star_output/{sample}.sorted.bam"
    output:
        collatedbam = "srna/outs/{sample}/star_output/{sample}.collated.bam",
    conda:
        "omics"
    benchmark:
        "srna/benchmarks/collateBam/{sample}.tsv"
    resources:
        mem_mb  = 128000,
        runtime = 60
    shell:
        """
samtools collate -o {output.collatedbam} {input.sortedBam}
        """

rule telescope:
    input:
        collatedbam = "srna/outs/{sample}/star_output/{sample}.collated.bam",
        libtype = "srna/qc/library_type.txt",
    params:
        strandparam = getTelescopeStrandParam(),
        gff = lambda wildcards: "aref/default/%s_annotations/%s_repeatmasker.gff2"%(wildcards.sample, wildcards.sample) if config["srna"]["per_sample_ref"] == "yes" else "aref/default/A.REF_annotations/A.REF_repeatmasker.gff2"
    retries: 3
    output:
        counts = "srna/outs/{sample}/telescope/telescope-run_stats.tsv"
    benchmark:
        "srna/benchmarks/telescope/{sample}.tsv"
    threads: 4
    conda:
        "telescope3"
    resources:
        mem_mb  = 128000,
        runtime = 600
    shell: 
        """
echo {params.strandparam}
telescope assign \
--attribute gene_id \
--ncpu 1 \
--stranded_mode {params.strandparam} \
--outdir $(dirname {output.counts}) \
{input.collatedbam} \
{params.gff}
        """

rule tpm:
    input:
        counts = "srna/outs/agg/featurecounts_genes/counts.txt",
        rte_counts = expand("srna/outs/{sample}/telescope/telescope-run_stats.tsv", sample = samples)
    params:
        sample_table = config["srna"]["sample_table"],
        contrasts = config["srna"]["contrasts"],
        levels = config["srna"]["levels"],
        annotation_genes = config["srna"]["annotation_genes"],
        r_annotation_fragmentsjoined = config["srna"]["r_annotation_fragmentsjoined"],
        r_repeatmasker_annotation = config["srna"]["r_repeatmasker_annotation"],
        counttype = lambda w: w.counttype
    benchmark:
        "srna/benchmarks/tpm/{counttype}.tsv"
    resources:
        mem_mb = 100000
    conda: "evo2"
    wildcard_constraints:
        counttype="[A-Za-z0-9_]+"
    output:
        tpm = "srna/outs/agg/tpm/{counttype}/tpmdf.tsv"
    script:
        "scripts/tpm.R"

rule deseq:
    input:
        counts = "srna/outs/agg/featurecounts_genes/counts.txt",
        rte_counts = expand("srna/outs/{sample}/telescope/telescope-run_stats.tsv", sample = samples)
    params:
        sample_table = config["srna"]["sample_table"],
        contrasts = config["srna"]["contrasts"],
        levels = config["srna"]["levels"],
        paralellize_bioc = config["srna"]["paralellize_bioc"],
        counttype = lambda w: w.counttype,
        outputdir =lambda w, output: os.path.dirname(os.path.dirname(output.counts_normed)),
    benchmark:
        "srna/benchmarks/deseq/{counttype}.tsv"
    resources:
        cpus_per_task =10,
        mem_mb = 240000,
        runtime = 1000
    conda: "deseq"
    wildcard_constraints:
        counttype="[A-Za-z0-9_]+"
    output:
        results_genes = expand("srna/results/agg/deseq/{{counttype}}/{contrast}/results_genes.csv", contrast = config["srna"]["contrasts"]),
        results_rtes = expand("srna/results/agg/deseq/{{counttype}}/{contrast}/results_rtes.csv", contrast = config["srna"]["contrasts"]),
        counts_normed = "srna/results/agg/deseq/{counttype}/counttablesizenormed.csv",
        sizefactors = "srna/results/agg/deseq/{counttype}/sizefactors.csv",
        environment = "srna/results/agg/deseq/{counttype}/deseq_environment.RData",
        report = report(
            directory("srna/results/agg/deseq/{counttype}"),
            patterns=["{gene_or_te}/{name}.pdf"],
            category="Differential Expression {counttype}",
            subcategory="{gene_or_te}")
    script:
        "scripts/deseq.R"

rule consolidateDeseqResults:
    input:
        results = expand("srna/results/agg/deseq/{counttype}/{contrast}/results_rtes.csv", contrast = config["srna"]["contrasts"], counttype = config["srna"]["counttypes"]),
        counts_normed = expand("srna/results/agg/deseq/{counttype}/counttablesizenormed.csv", counttype = config["srna"]["counttypes"])
    params:
        inputdir = "srna/results/agg/deseq",
        outputdir = "srna/results/agg/deseq",
        module_name = "srna"
    benchmark:
        "srna/benchmarks/consolidateDeseqResults/consolidateDeseqResults.tsv"
    conda:
        "repeatanalysis"
    resources:
        cpus_per_task =10,
        mem_mb = 164000,
        runtime = 300
    output:
        resultsdf = "srna/results/agg/deseq/resultsdf.tsv"
    script:
        "scripts/consolidateDeseqResults.R"

#tag ENRICHMENT ANALYSIS
import os
rule enrichment_analysis:
    input:
        resultsdf ="srna/results/agg/deseq/resultsdf.tsv"
    params:
        inputdir =lambda w, input: os.path.dirname(os.path.dirname(input.resultsdf)),
        contrasts = config["srna"]["contrasts"],
        genesets_for_heatmaps = config["srna"]["genesets_for_heatmaps"],
        collections_for_gsea = config["srna"]["collections_for_gsea"],
        sample_table = config["srna"]["sample_table"],
        outputdir =lambda w, output: os.path.dirname(output.environment),
        module_name = "srna"
    benchmark:
        "srna/benchmarks/enrichment_analysis/enrichment_analysis.tsv"
    conda:
        "ea"
    resources:
        cpus_per_task =10,
        mem_mb = 164000,
        runtime = 300
    output:
        results_table_unbiased = "srna/results/agg/enrichment_analysis/results_table_unbiased.tsv",
        environment = "srna/results/agg/enrichment_analysis/enrichment_analysis_environment.RData",
        report = report(
            directory("srna/results/agg/enrichment_analysis"),
            patterns=["gsea_top_{name}_grid_1.pdf", "{leading_path}heatmap_{trailingpath}.pdf"],
            category="Gene Enrichment")
    script:
        "scripts/ea.R"

rule enrichment_analysis_repeats:
    input:
        resultsdf ="srna/results/agg/deseq/resultsdf.tsv",
    params:
        inputdir =lambda w, input: os.path.dirname(os.path.dirname(input.resultsdf)),
        contrasts = config["srna"]["contrasts"],
        counttype = lambda w: w.counttype, 
        sample_table = config["srna"]["sample_table"],
        outputdir = lambda w, output: os.path.dirname(output.environment),
        r_annotation_fragmentsjoined = config["srna"]["r_annotation_fragmentsjoined"],
        r_repeatmasker_annotation = config["srna"]["r_repeatmasker_annotation"],
        module_name = "srna"
    benchmark:
        "srna/benchmarks/enrichment_analysis_repeats/{counttype}.tsv"
    conda:
        "ea"
    resources:
        cpus_per_task =10,
        mem_mb = 164000,
        runtime = 300
    output:
        results_table = "srna/results/agg/enrichment_analysis_repeats/{counttype}/results_table.tsv",
        environment = "srna/results/agg/enrichment_analysis_repeats/{counttype}/enrichment_analysis_repeats_environment.RData",
        report = report(
            directory("srna/results/agg/enrichment_analysis_repeats/{counttype}"),
            patterns=["std/gsea_top_{name}.pdf"],
            category="RTE Enrichment {counttype}")

    script:
        "scripts/ea_repeats.R"

rule repeatanalysis_plots:
    input:
        resultsdf = "srna/results/agg/deseq/resultsdf.tsv"
    params:
        counttype = lambda w: w.counttype,
        contrasts = config["srna"]["contrasts"],
        inputdir = lambda w, input: os.path.dirname(input.resultsdf),
        outputdir = lambda w, output: os.path.dirname(os.path.dirname(output.environment)),
        r_annotation_fragmentsjoined = config["srna"]["r_annotation_fragmentsjoined"],
        r_repeatmasker_annotation = config["srna"]["r_repeatmasker_annotation"],
        module_name = "srna"
    benchmark:
        "srna/benchmarks/repeatanalysis_plots/{counttype}.tsv"
    conda:
        "repeatanalysis"
    resources:
        cpus_per_task =10,
        mem_mb = 200000,
        runtime = 500
    output:
        environment = "srna/results/agg/repeatanalysis/{counttype}/repeatanalysisplots_environment.RData", 
        report = report(
            directory("srna/results/agg/repeatanalysis/{counttype}"),
            patterns=["pan_contrast/{rte}_{restofstring}.pdf", "{contrast}/{rte}_{restofstring}rte_length_req_genic_loc.pdf"],
            category="Repeat Analysis {counttype}")
    script:
        "scripts/repeatanalysisPlots.R"


rule characterize_tpm:
    input:
        tpm = "srna/outs/agg/tpm/{counttype}/tpmdf.tsv"
    params:
        counttype = lambda w: w.counttype,
        outputdir = lambda w, output: os.path.dirname(os.path.dirname(output.environment)),
        r_annotation_fragmentsjoined = config["srna"]["r_annotation_fragmentsjoined"],
        r_repeatmasker_annotation = config["srna"]["r_repeatmasker_annotation"],
        refseq = config["srna"]["annotation_genes"],
        ref = "aref/default/A.REF.fa",
        annotation_genes = config["srna"]["annotation_genes"],
        module_name = "srna"
    benchmark:
        "srna/benchmarks/repeatanalysis_plots/{counttype}.tsv"
    conda:
        "repeatanalysis"
    resources:
        cpus_per_task =10,
        mem_mb = 200000,
        runtime = 500
    output:
        environment = "srna/results/agg/tpm_sources/{counttype}/characterize_tpm_environment.RData",
        report = report(
            directory("srna/results/agg/tpm_sources/{counttype}"),
            patterns=["{group}/{restofstring}.pdf", "{group}/{restofstring}.pdf"],
            category="TPM Characterization {counttype}",
            subcategory="{group}")
    script:
        "scripts/characterize_samples.R"




# def bigwig_sizefactor_input(wildcards):
#     sizefactor_path = "srna/results/agg/deseq/%s/sizefactors.csv"%(config["srna"]["counttypes"][0])
#     if not Path(sizefactor_path).exists():
#         return "NA"
#     else:
#         return 1/float(pd.read_csv("srna/results/agg/deseq/%s/sizefactors.csv"%(config["srna"]["counttypes"][0])).set_index("sample_name").loc[wildcards.sample, "sizefactor"])

rule getBigWigF:
    input:
        sortedbam = "srna/outs/{sample}/star_output/{sample}.sorted.primary.bam"
    params:
        rna_strand_param = lambda w: "reverse" if inferLibraryType() == "forward" else "forward"
    output:
        bwF = "srna/outs/{sample}/star_output/{sample}.F.bw"
    benchmark:
        "srna/benchmarks/getBigWigF/{sample}.tsv"
    resources:
        cpus_per_task =10,
        mem_mb = 10000,
        runtime = 300
    conda:
        "deeptools"
    shell: "bamCoverage -b {input.sortedbam} -o {output.bwF} --numberOfProcessors max  --samFlagExclude 256 --filterRNAstrand {params.rna_strand_param} --binSize 50"
# --scaleFactor {params.sample_size_factor}
#The --filterRNAstrand option assumes the sequencing library generated from ILLUMINA
# dUTP/NSR/NNSR methods, which are the most commonly used method for library preparation, 
#where Read 2 (R2) is in the direction of RNA strand (reverse-stranded library). 
#However other methods exist, which generate read R1 in the direction of RNA strand 
#(see this review). For these libraries, --filterRNAstrand will have an opposite behavior, 
#i.e. --filterRNAstrand forward will give you reverse strand signal and vice-versa.
#https://www.biostars.org/p/413626/#414440 useful thread about scaling factors

rule getBigWigR:
    input:
        sortedbam = "srna/outs/{sample}/star_output/{sample}.sorted.primary.bam"
    params:
        rna_strand_param = lambda w: "forward" if inferLibraryType() == "forward" else "reverse"
    output:
        bwR = "srna/outs/{sample}/star_output/{sample}.R.bw"
    benchmark:
        "srna/benchmarks/getBigWigR/{sample}.tsv"
    resources:
        cpus_per_task =10,
        mem_mb = 10000,
        runtime = 300
    conda:
        "deeptools"
    shell: "bamCoverage -b {input.sortedbam} -o {output.bwR} --numberOfProcessors max  --samFlagExclude 256 --filterRNAstrand {params.rna_strand_param} --binSize 50"
# --scaleFactor {params.sample_size_factor}
#The --filterRNAstrand option assumes the sequencing library generated from ILLUMINA
# dUTP/NSR/NNSR methods, which are the most commonly used method for library preparation, 
#where Read 2 (R2) is in the direction of RNA strand (reverse-stranded library). 
#However other methods exist, which generate read R1 in the direction of RNA strand 
#(see this review). For these libraries, --filterRNAstrand will have an opposite behavior, 
#i.e. --filterRNAstrand forward will give you reverse strand signal and vice-versa.
#https://www.biostars.org/p/413626/#414440 useful thread about scaling factors

rule bigwigplots:
    input:
        bwF = expand("srna/outs/{sample}/star_output/{sample}.F.bw", sample = samples),
        bwR = expand("srna/outs/{sample}/star_output/{sample}.R.bw", sample = samples),
        multiqc = "srna/qc/multiqc/multiqc_report.html"
    params:
        r_annotation_fragmentsjoined = config["srna"]["r_annotation_fragmentsjoined"],
        r_repeatmasker_annotation = config["srna"]["r_repeatmasker_annotation"],
        txdbrefseq = "aref/default/A.REF_annotations/refseq.sqlite"
    benchmark:
        "srna/benchmarks/bigwigplots/bigwigplots.tsv"
    output:
        environment = "srna/results/agg/bigwig_plots/bigwigplots_environment.RData",
        report = report(
            directory("srna/results/agg/bigwig_plots"),
            patterns=["{sub_grouping}/{name}.pdf"],
            category="BigWig Analysis",
            subcategory="{sub_grouping}")
    resources:
        cpus_per_task =10,
        mem_mb = 40000
    conda:
        "repeatanalysis"
    script: "scripts/bigwig_analysis.R"

rule fpkm:
    input:
        sortedbam = "srna/outs/{sample}/star_output/{sample}.sorted.primary.bam"
    params:
        bed = "aref/default/A.REF_annotations/A.REF_repeatmasker.complete.bed",
        FpkmCountStrandParam = getFpkmCountStrandParam()
    output:
        values = "srna/outs/{sample}/star_output/{sample}.fpkm"
    benchmark:
        "srna/benchmarks/fpkm/{sample}.tsv"
    resources:
        cpus_per_task =10,
        mem_mb = 10000,
        runtime = 60
    conda:
        "rseqc"
    shell:
        """
output_path={output.values}
FPKM_count.py -i {input.sortedbam} -o ${{output_path%.*}} -r {params.bed} -d {params.FpkmCountStrandParam} -q 1
        """